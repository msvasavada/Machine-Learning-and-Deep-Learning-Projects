{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"authorship_tag":"ABX9TyMzeGAeNRa8sAISg4Xbfbep"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPjEb0exH1dk","executionInfo":{"status":"ok","timestamp":1652752412703,"user_tz":240,"elapsed":22185,"user":{"displayName":"Meghana Vasavada","userId":"00617974796199149976"}},"outputId":"409a80d4-ab06-47da-e7c1-39f07038c29c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","import os\n","import time\n","import pprint\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","from tensorflow.keras.utils import to_categorical\n","\n","from PIL import Image\n","from osgeo import gdal"]},{"cell_type":"code","source":["bc_data = r'/content/drive/MyDrive/Land Cover Classification with Sentinel-2/BC_input_data.CSV'\n","df_bc = pd.read_csv(bc_data)\n","on_data = r'/content/drive/MyDrive/Land Cover Classification with Sentinel-2/BC_input_data.CSV'\n","df_on = pd.read_csv(on_data)\n"],"metadata":{"id":"EdM1QyOdIr4Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load dataset in train/test variables\n","def load_dataset(df_train, df_test, num_classes):\n","    \n","    df_train = np.array(df_train).reshape( len(df_train), 1, -1 )\n","    trainX, trainy = df_train[:,:,0:-1], to_categorical(df_train[:,:,-1], num_classes=num_classes)  # one hot encode y\n","    \n","    df_test = np.array(df_test).reshape( len(df_test), 1, -1 )\n","    testX, testy = df_test[:,:,0:-1], to_categorical(df_test[:,:,-1], num_classes=num_classes)  # one hot encode y\n","    \n","    return trainX, trainy, testX, testy\n","\n","# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy):\n","    verbose, epochs, batch_size = 1, 50, 10000\n","    n_features, n_outputs = trainX.shape[2], trainy.shape[-1]\n","    model = models.Sequential()\n","    model.add(layers.Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(1, n_features),padding='same'))\n","    model.add(layers.BatchNormalization())\n","    #model.add(layers.Dropout({{uniform(0, 1)}}))\n","    model.add(layers.Dropout(0.3))\n","    model.add(layers.Conv1D(filters=64, kernel_size=1, activation='relu',padding='same'))\n","    model.add(layers.BatchNormalization())\n","    #model.add(layers.Dropout({{uniform(0, 1)}}))\n","    model.add(layers.Dropout(0.8))\n","    model.add(layers.MaxPooling1D(pool_size=1))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(100, activation='relu'))\n","    model.add(layers.Dense(n_outputs, activation='softmax'))\n","    opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n","    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    # fit network\n","    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","    # evaluate model\n","    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n","    return accuracy\n","       \n","    \n","# run an experiment\n","def run_experiment(repeats=1):\n","    # load data\n","    trainX, trainy, testX, testy = load_dataset(df_on, df_bc, num_classes=20)  \n","    \n","    # repeat experiment\n","    scores = list()\n","    for r in range(repeats):\n","        score = evaluate_model(trainX, trainy, testX, testy)\n","        score = score * 100.0\n","        print('>#%d: %.3f' % (r+1, score))\n","        scores.append(score)\n","        \n","    # summarize results\n","    m, s = np.mean(scores), np.std(scores)\n","    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"],"metadata":{"id":"57dRiK7cJJpu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["st = time.time()\n","run_experiment(repeats=2)\n","print( f'Total Elapsed time = {(time.time() - st)/60 :.1f} min')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrrKGVzWJPFc","executionInfo":{"status":"ok","timestamp":1651792526177,"user_tz":240,"elapsed":4379941,"user":{"displayName":"Meghana Vasavada","userId":"00617974796199149976"}},"outputId":"55b7f402-de69-42e7-99e5-ed54d991463a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","512/512 [==============================] - 44s 82ms/step - loss: 1.0992 - accuracy: 0.6079\n","Epoch 2/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9817 - accuracy: 0.6402\n","Epoch 3/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9728 - accuracy: 0.6427\n","Epoch 4/50\n","512/512 [==============================] - 49s 96ms/step - loss: 0.9686 - accuracy: 0.6444\n","Epoch 5/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9683 - accuracy: 0.6445\n","Epoch 6/50\n","512/512 [==============================] - 44s 87ms/step - loss: 0.9703 - accuracy: 0.6439\n","Epoch 7/50\n","512/512 [==============================] - 43s 85ms/step - loss: 0.9694 - accuracy: 0.6440\n","Epoch 8/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9691 - accuracy: 0.6443\n","Epoch 9/50\n","512/512 [==============================] - 43s 85ms/step - loss: 0.9705 - accuracy: 0.6439\n","Epoch 10/50\n","512/512 [==============================] - 43s 85ms/step - loss: 0.9708 - accuracy: 0.6443\n","Epoch 11/50\n","512/512 [==============================] - 44s 85ms/step - loss: 0.9724 - accuracy: 0.6439\n","Epoch 12/50\n","512/512 [==============================] - 43s 85ms/step - loss: 0.9720 - accuracy: 0.6437\n","Epoch 13/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9730 - accuracy: 0.6435\n","Epoch 14/50\n","512/512 [==============================] - 43s 85ms/step - loss: 0.9761 - accuracy: 0.6425\n","Epoch 15/50\n","512/512 [==============================] - 44s 85ms/step - loss: 0.9739 - accuracy: 0.6433\n","Epoch 16/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9733 - accuracy: 0.6430\n","Epoch 17/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9742 - accuracy: 0.6429\n","Epoch 18/50\n","512/512 [==============================] - 44s 85ms/step - loss: 0.9738 - accuracy: 0.6426\n","Epoch 19/50\n","512/512 [==============================] - 44s 85ms/step - loss: 0.9745 - accuracy: 0.6427\n","Epoch 20/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9749 - accuracy: 0.6423\n","Epoch 21/50\n","512/512 [==============================] - 41s 81ms/step - loss: 0.9771 - accuracy: 0.6419\n","Epoch 22/50\n","512/512 [==============================] - 41s 81ms/step - loss: 0.9758 - accuracy: 0.6422\n","Epoch 23/50\n","512/512 [==============================] - 42s 81ms/step - loss: 0.9751 - accuracy: 0.6425\n","Epoch 24/50\n","512/512 [==============================] - 42s 81ms/step - loss: 0.9764 - accuracy: 0.6419\n","Epoch 25/50\n","512/512 [==============================] - 42s 83ms/step - loss: 0.9767 - accuracy: 0.6415\n","Epoch 26/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9760 - accuracy: 0.6424\n","Epoch 27/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9752 - accuracy: 0.6422\n","Epoch 28/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9900 - accuracy: 0.6377\n","Epoch 29/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9819 - accuracy: 0.6402\n","Epoch 30/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9756 - accuracy: 0.6423\n","Epoch 31/50\n","512/512 [==============================] - 42s 83ms/step - loss: 0.9779 - accuracy: 0.6415\n","Epoch 32/50\n","512/512 [==============================] - 42s 83ms/step - loss: 0.9756 - accuracy: 0.6426\n","Epoch 33/50\n","512/512 [==============================] - 42s 83ms/step - loss: 0.9773 - accuracy: 0.6420\n","Epoch 34/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9787 - accuracy: 0.6419\n","Epoch 35/50\n","512/512 [==============================] - 42s 83ms/step - loss: 0.9823 - accuracy: 0.6405\n","Epoch 36/50\n","512/512 [==============================] - 45s 88ms/step - loss: 0.9745 - accuracy: 0.6432\n","Epoch 37/50\n","512/512 [==============================] - 44s 85ms/step - loss: 0.9756 - accuracy: 0.6429\n","Epoch 38/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9762 - accuracy: 0.6429\n","Epoch 39/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9774 - accuracy: 0.6426\n","Epoch 40/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9864 - accuracy: 0.6397\n","Epoch 41/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9821 - accuracy: 0.6411\n","Epoch 42/50\n","512/512 [==============================] - 43s 83ms/step - loss: 0.9759 - accuracy: 0.6429\n","Epoch 43/50\n","512/512 [==============================] - 43s 83ms/step - loss: 0.9819 - accuracy: 0.6409\n","Epoch 44/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9843 - accuracy: 0.6398\n","Epoch 45/50\n","512/512 [==============================] - 43s 83ms/step - loss: 0.9819 - accuracy: 0.6412\n","Epoch 46/50\n","512/512 [==============================] - 43s 83ms/step - loss: 0.9802 - accuracy: 0.6414\n","Epoch 47/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9836 - accuracy: 0.6402\n","Epoch 48/50\n","512/512 [==============================] - 43s 83ms/step - loss: 0.9750 - accuracy: 0.6433\n","Epoch 49/50\n","512/512 [==============================] - 42s 82ms/step - loss: 0.9931 - accuracy: 0.6380\n","Epoch 50/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9798 - accuracy: 0.6414\n",">#1: 52.959\n","Epoch 1/50\n","512/512 [==============================] - 45s 86ms/step - loss: 1.1057 - accuracy: 0.6089\n","Epoch 2/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9885 - accuracy: 0.6381\n","Epoch 3/50\n","512/512 [==============================] - 44s 85ms/step - loss: 0.9720 - accuracy: 0.6434\n","Epoch 4/50\n","512/512 [==============================] - 44s 87ms/step - loss: 0.9659 - accuracy: 0.6453\n","Epoch 5/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9642 - accuracy: 0.6459\n","Epoch 6/50\n","512/512 [==============================] - 44s 85ms/step - loss: 0.9629 - accuracy: 0.6464\n","Epoch 7/50\n","512/512 [==============================] - 44s 85ms/step - loss: 0.9640 - accuracy: 0.6461\n","Epoch 8/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9629 - accuracy: 0.6468\n","Epoch 9/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9629 - accuracy: 0.6466\n","Epoch 10/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9637 - accuracy: 0.6468\n","Epoch 11/50\n","512/512 [==============================] - 44s 85ms/step - loss: 0.9653 - accuracy: 0.6458\n","Epoch 12/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9648 - accuracy: 0.6460\n","Epoch 13/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9653 - accuracy: 0.6458\n","Epoch 14/50\n","512/512 [==============================] - 45s 87ms/step - loss: 0.9651 - accuracy: 0.6460\n","Epoch 15/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9829 - accuracy: 0.6410\n","Epoch 16/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9675 - accuracy: 0.6458\n","Epoch 17/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9670 - accuracy: 0.6459\n","Epoch 18/50\n","512/512 [==============================] - 45s 88ms/step - loss: 0.9659 - accuracy: 0.6460\n","Epoch 19/50\n","512/512 [==============================] - 45s 87ms/step - loss: 0.9671 - accuracy: 0.6457\n","Epoch 20/50\n","512/512 [==============================] - 44s 87ms/step - loss: 0.9680 - accuracy: 0.6456\n","Epoch 21/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9672 - accuracy: 0.6459\n","Epoch 22/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9685 - accuracy: 0.6452\n","Epoch 23/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9705 - accuracy: 0.6449\n","Epoch 24/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9737 - accuracy: 0.6441\n","Epoch 25/50\n","512/512 [==============================] - 44s 87ms/step - loss: 0.9712 - accuracy: 0.6447\n","Epoch 26/50\n","512/512 [==============================] - 43s 83ms/step - loss: 0.9736 - accuracy: 0.6435\n","Epoch 27/50\n","512/512 [==============================] - 43s 84ms/step - loss: 0.9972 - accuracy: 0.6356\n","Epoch 28/50\n","512/512 [==============================] - 43s 84ms/step - loss: 1.0683 - accuracy: 0.6061\n","Epoch 29/50\n","512/512 [==============================] - 43s 84ms/step - loss: 1.0292 - accuracy: 0.6206\n","Epoch 30/50\n","512/512 [==============================] - 44s 87ms/step - loss: 1.0166 - accuracy: 0.6250\n","Epoch 31/50\n","512/512 [==============================] - 43s 84ms/step - loss: 1.0082 - accuracy: 0.6285\n","Epoch 32/50\n","512/512 [==============================] - 43s 84ms/step - loss: 1.0222 - accuracy: 0.6258\n","Epoch 33/50\n","512/512 [==============================] - 45s 88ms/step - loss: 1.0072 - accuracy: 0.6302\n","Epoch 34/50\n","512/512 [==============================] - 45s 87ms/step - loss: 1.0002 - accuracy: 0.6327\n","Epoch 35/50\n","512/512 [==============================] - 45s 87ms/step - loss: 0.9964 - accuracy: 0.6338\n","Epoch 36/50\n","512/512 [==============================] - 45s 87ms/step - loss: 0.9945 - accuracy: 0.6344\n","Epoch 37/50\n","512/512 [==============================] - 44s 87ms/step - loss: 0.9907 - accuracy: 0.6357\n","Epoch 38/50\n","512/512 [==============================] - 44s 87ms/step - loss: 0.9892 - accuracy: 0.6361\n","Epoch 39/50\n","512/512 [==============================] - 44s 86ms/step - loss: 0.9916 - accuracy: 0.6358\n","Epoch 40/50\n","512/512 [==============================] - 44s 87ms/step - loss: 0.9906 - accuracy: 0.6360\n","Epoch 41/50\n","512/512 [==============================] - 45s 87ms/step - loss: 0.9938 - accuracy: 0.6351\n","Epoch 42/50\n","512/512 [==============================] - 45s 87ms/step - loss: 0.9889 - accuracy: 0.6366\n","Epoch 43/50\n","512/512 [==============================] - 45s 88ms/step - loss: 0.9868 - accuracy: 0.6376\n","Epoch 44/50\n","512/512 [==============================] - 45s 87ms/step - loss: 0.9842 - accuracy: 0.6388\n","Epoch 45/50\n","512/512 [==============================] - 45s 88ms/step - loss: 0.9812 - accuracy: 0.6400\n","Epoch 46/50\n","512/512 [==============================] - 45s 87ms/step - loss: 0.9838 - accuracy: 0.6396\n","Epoch 47/50\n","512/512 [==============================] - 44s 87ms/step - loss: 0.9855 - accuracy: 0.6389\n","Epoch 48/50\n","512/512 [==============================] - 45s 87ms/step - loss: 0.9844 - accuracy: 0.6392\n","Epoch 49/50\n","512/512 [==============================] - 44s 87ms/step - loss: 0.9872 - accuracy: 0.6383\n","Epoch 50/50\n","512/512 [==============================] - 45s 87ms/step - loss: 1.1134 - accuracy: 0.6181\n",">#2: 45.805\n","Accuracy: 49.382% (+/-3.577)\n","Total Elapsed time = 73.0 min\n"]}]},{"cell_type":"code","source":["def learning_curve(history, epoch):\n","\n","  # training vs validation accuracy\n","  epoch_range = range(1, epoch+1)\n","  plt.plot(epoch_range, history.history['accuracy'])\n","  plt.plot(epoch_range, history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train', 'val'], loc='upper left')\n","  plt.show()\n","\n","  # training vs validation loss\n","  plt.plot(epoch_range, history.history['loss'])\n","  plt.plot(epoch_range, history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train', 'val'], loc='upper left')\n","  plt.show()"],"metadata":{"id":"boDks3jrQQDa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data <- pd.dataFrame(feature = rep(5, 5),\n","                   year = seq(2011, 2015), \n","                   target = c(1, 0, 1, 0, 0))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"DXhRRAU3t7uT","executionInfo":{"status":"error","timestamp":1652752486611,"user_tz":240,"elapsed":147,"user":{"displayName":"Meghana Vasavada","userId":"00617974796199149976"}},"outputId":"b76ba1b0-2e24-47c9-f3bf-d00cf435f1b5"},"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-6fd18d6d5e67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data <- pd.dataFrame(feature = rep(5, 5),\n\u001b[0m\u001b[1;32m      2\u001b[0m                    \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2011\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    target = c(1, 0, 1, 0, 0))\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]}]}